##用户端使用手册
    
    工作逻辑——
        所有IP拥有数据提供者和运算者两种身份，第一种身份上传用户希望运算的数据文件和对应执行该运算的函数文件，第二种身份申请数据集运算并返回运算值
        1.数据提供者
            数据提供者将函数文件放置于upload_functions文件夹中，不能存在文件夹，必须是所有文件在该目录下，命名规则为——”用户自定的该函数希望运算IP的能力等级“+”-“+”函数的名字“+".py",比如一个电力大数据运算函数文件，希望运算的IP能力等级在5级（1-5，越高能力越强），函数名为electric，函数文件名字为”5-electric.py“
            完成之后运行upload_func.py文件
            数据提供者将数据文件放置于upload_data文件夹中，文件名为对应的函数名字，”electric.pkl“,电力大数据和大整数分解目前不支持文件夹嵌套，只能是把文件全部放在该目录下，文本处理任务支持文件嵌套，但是文件夹名字必须为对应函数名字，比如测试的金庸和古龙小说，应该全部放在NLP文件夹下，txt文件可以出现在NLP下的每一级文件夹中
            完成之后运行upload_data.py文件
        2.运算者
            运算者需要先同步所有存储在后台中的函数文件，对的，目前是所有，因为后台中只根据用户ID做文件夹区分，没有日期的概念，我觉得没啥必要，所以就全下载了
            运行文件file_synchronization.py完成函数文件同步
            现在可以开始申请数据集了
            运行文件predict.py，开始持续申请数据集，若中断请重复运行此文件，还是不行的话进入dajngo管理后台，进入菜单——分级处理——用户，将该用户对应status——”空闲“点击为True状态后点击上方保存按钮，
            

## 函数文件上传至lzudatafatory中去     
##上传的函数文件函数代码格式请按照upload_function文件夹中示例
##上传的数据文件只有文字处理可以有文件夹嵌套
##上传流程中函数可以反复上传，但是数据文件只能上传一次，实际上上传之后所有的文件就被打包到upload_data_backup文件夹中